\documentclass{report}
\usepackage{amsmath}
\title{High Performance Scientific Computing Assignment Results}
\author{Saran S \\ 133106001}
\begin{document}
\maketitle
\section*{Results}
\begin{table}[h]
\caption{Results obtained}
\centering
\begin{tabular}{lcccc}
\hline 
Method & NP & \multicolumn{3}{c}{Matrix Size} \\ %[1ex]
       &    & 100      & 1000     & 4000 \\ %[0.5ex]
\hline 
Serial & 1  & 0.015811 & 9.953883 & 942.824617 \\  \hline
       & 2  & 0.011148 & 5.549039 & 630.521049 \\
OpenMP & 4  & 0.014142 & 5.452055 & 593.671016 \\
       & 8  & 0.013193 & 5.513008 & 743.228705 \\
       & 16 & 0.013232 & 5.548083 & 698.820082 \\ \hline
       & 2  & \textbf{0.003194} & 5.535810 & \textbf{532.905690} \\
MPI & 4  & 0.005791 & \textbf{5.373600} & 754.417009 \\
       & 8  & 0.006241 & 5.507608 & 751.221100 \\
       & 16 & 0.027094 & 5.921839 & 1250.199082 \\ \hline
              

\end{tabular}
\end{table}
\begin{flushleft}
\textit{Specification of system used} : Intel Core i5 - 3317U (2 cores capable of 4 threads at a time) with a clockspeed 1.7 GHz and 4 GB Ram (1600 MHz).\\
\textit{Programming language} :  C
\end{flushleft}
Time (seconds) taken for three different matrix dimensions for serial, OpenMP and MPI code is tabulated below. Highlighted time indicates the fastest performance in the lot for particular matrix size. When the number of processors used go beyond the maximum threads  available in the system at a particular time, here 4, as expected the results shows increase in time for calculations. The effect of parallel computing is visible only when the problem size goes beyond a limit, since initialization and run of OpenMP or MPI has its own effective weightage on the total run time, but nullified when the problem size is large enough.    


\end{document}